{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m BayesianRidge, LinearRegression\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionTreeRegressor\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All models to test\n",
    "allm = {}\n",
    "allm[\"linear\"] = LinearRegression()\n",
    "allm[\"bayesian\"] = BayesianRidge(compute_score=True)\n",
    "allm[\"dt5\"] = DecisionTreeRegressor(max_depth=5)\n",
    "allm[\"dt10\"] = DecisionTreeRegressor(max_depth=10)\n",
    "allm[\"dt15\"] = DecisionTreeRegressor(max_depth=15)\n",
    "allm[\"rf5\"] = RandomForestRegressor(n_estimators=200)\n",
    "allm[\"ada\"] = AdaBoostRegressor(n_estimators=200)\n",
    "allm[\"gb2005\"] = GradientBoostingRegressor(n_estimators=200, max_depth=5)\n",
    "allm[\"gb2008\"] = GradientBoostingRegressor(n_estimators=500, max_depth=8)\n",
    "allm[\"mlp200\"] = MLPRegressor(hidden_layer_sizes=(200,), max_iter=5000)\n",
    "allm[\"mlp400\"] = MLPRegressor(hidden_layer_sizes=(400,), max_iter=5000)\n",
    "allm[\"mlp200200\"] = MLPRegressor(hidden_layer_sizes=(200,200), max_iter=5000)\n",
    "allm[\"mlp20050\"] = MLPRegressor(hidden_layer_sizes=(200,50), max_iter=5000)\n",
    "allm[\"gpr\"] = GaussianProcessRegressor(kernel=DotProduct() + WhiteKernel())\n",
    "allm[\"lasso\"] = Lasso(alpha=0.1)\n",
    "allm[\"ridge\"] = Ridge(alpha=0.1)\n",
    "allm[\"elastic\"] = ElasticNet(alpha=0.1, l1_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tts(X, Y, train_size = 1000):\n",
    "    \"\"\"\n",
    "    Custom train test split to ensure even distribution of extreme drag values across train and test sets\n",
    "    Input: X, Y, train_size\n",
    "    Output: X_train, X_test, Y_train, Y_test\n",
    "    \"\"\"\n",
    "    total_df = X.join(Y)\n",
    "    total_df = total_df.sort_values(by=\"drag\")\n",
    "    select = np.linspace(0, len(total_df)-1, train_size, dtype=int)\n",
    "    select = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tts(data, test_prop=0.1):\n",
    "    \"\"\"\n",
    "    Input: data list, train_num\n",
    "    Output: train, test\n",
    "    1. puts data in same dataframe\n",
    "    2. sorts data by drag force in target vals\n",
    "    3. splits data into train and test\n",
    "    \"\"\"\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=test_prop, random_state=20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_vals, target_vals, stratify=sss.split(input_vals, target_vals))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange and rename columns of aero dataset\n",
    "# Original:['SaddleY@Mainsketch', 'UpperLeg@Mainsketch', 'HandleX@Mainsketch',\n",
    "# 'HandleY@Mainsketch', 'Arm@Mainsketch', 'SaddleX+.2@Mainsketch',\n",
    "# 'CrankLength@Mainsketch', 'LowerLeg@Mainsketch',\n",
    "# 'TorsoLength@Mainsketch', 'Neckandhead@Mainsketch',\n",
    "# 'TorsoWidth@Widthdef', 'Back Vertical Height', 'Head Height',\n",
    "# 'Theigh Width', 'legarea', 'Frontal Surface Area']\n",
    "# Result: ['hx', 'hy', 'sx', 'sy', 'cl', 'll', 'ul', 'tl', 'al', 'sw', 'ht', 'hb', 'back vertical height', 'head height', 'thigh width', 'leg area', 'frontal surface area']\n",
    "\n",
    "in_df = pd.read_csv(\"aero.csv\")\n",
    "out_df = in_df[[\"HandleX@Mainsketch\", \"HandleY@Mainsketch\", \"SaddleX+.2@Mainsketch\", \"SaddleY@Mainsketch\", \"CrankLength@Mainsketch\", \"LowerLeg@Mainsketch\", \"UpperLeg@Mainsketch\", \"TorsoLength@Mainsketch\", \"Arm@Mainsketch\", \"Neckandhead@Mainsketch\", \"TorsoWidth@Widthdef\", \"Back Vertical Height\", \"Head Height\", \"Theigh Width\", \"legarea\", \"Frontal Surface Area\"]]\n",
    "out_df.columns = [\"hx\", \"hy\", \"sx\", \"sy\", \"cl\", \"ll\", \"ul\", \"tl\", \"al\", \"head\", \"sw\", \"back vertical height\", \"head height\", \"thigh width\", \"leg area\", \"frontal surface area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(num_tests, data, method, train_size):\n",
    "    start_time = time.time()\n",
    "    total_score = 0\n",
    "    model = None\n",
    "    input_vals = data[0]\n",
    "    target_vals = data[1]\n",
    "    max_model = None\n",
    "    max_score = -1.0\n",
    "    for i in range(num_tests):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_vals, target_vals, train_size=train_size, shuffle=True)\n",
    "        match method:\n",
    "            case \"bayesian\":\n",
    "                model = BayesianRidge(compute_score=True)\n",
    "            case \"linear\":\n",
    "                model = LinearRegression()\n",
    "            case \"dt5\":\n",
    "                model = DecisionTreeRegressor(max_depth=5)\n",
    "            case \"dt8\":\n",
    "                model = DecisionTreeRegressor(max_depth=8)\n",
    "            case \"rf\":\n",
    "                model = RandomForestRegressor(n_estimators=200)\n",
    "            case \"ada\":\n",
    "                model = AdaBoostRegressor(n_estimators=200)\n",
    "            case \"gb\":\n",
    "                model = GradientBoostingRegressor(n_estimators=200, max_depth=3)\n",
    "            case \"mlp1\":\n",
    "                model = MLPRegressor(hidden_layer_sizes=(200,), max_iter=5000)\n",
    "            case \"mlp2\":\n",
    "                model = MLPRegressor(hidden_layer_sizes=(200, 200), max_iter=5000)\n",
    "            case \"gpr\":\n",
    "                kernel = DotProduct() + WhiteKernel()\n",
    "                model = GaussianProcessRegressor(kernel=kernel)\n",
    "            case _:\n",
    "                raise ValueError(\"Invalid method\")\n",
    "        model.fit(X_train, y_train)\n",
    "        cur_score = model.score(X_test, y_test)\n",
    "        total_score += cur_score\n",
    "        if cur_score > max_score:\n",
    "          max_score = cur_score\n",
    "          max_model = model\n",
    "    avg_score = total_score / num_tests\n",
    "    print(f\"Method: {method}, Score: {avg_score}, Time: {time.time() - start_time}\")\n",
    "    return avg_score, max_score, max_model\n",
    "\n",
    "\n",
    "\n",
    "def test_methods(input_vals, target_vals, train_size = 1000):\n",
    "    data = [input_vals, target_vals]\n",
    "    arow=pd.DataFrame({\"Linear Regression\": eval_score(100,data,\"linear\",train_size)},index=[len(data[0])])\n",
    "    arow=arow.join(pd.DataFrame({\"Bayesian Ridge Regression\": eval_score(100,data,\"bayesian\",train_size)},index=[len(data[0])]))\n",
    "    arow=arow.join(pd.DataFrame({\"Gaussian Process Regression\": eval_score(10,data,\"gpr\",train_size)},index=[len(data[0])]))\n",
    "    arow=arow.join(pd.DataFrame({\"Depth 5 Decision Tree\": eval_score(100,data,\"dt5\",train_size)},index=[len(data[0])]))\n",
    "    arow=arow.join(pd.DataFrame({\"Depth 8 Decision Tree\": eval_score(100,data,\"dt8\",train_size)},index=[len(data[0])]))\n",
    "    arow=arow.join(pd.DataFrame({\"Random Forest\": eval_score(10,data,\"rf\",train_size)},index=[len(data[0])]))\n",
    "    arow=arow.join(pd.DataFrame({\"AdaBoost\": eval_score(10,data,\"ada\",train_size)},index=[len(data[0])]))\n",
    "    arow=arow.join(pd.DataFrame({\"Gradient Boosting Regressor\": eval_score(10,data,\"gb\",train_size)},index=[len(data[0])]))\n",
    "    arow=arow.join(pd.DataFrame({\"3-layer Neural Net\": eval_score(5,data,\"mlp1\",train_size)},index=[len(data[0])]))\n",
    "    arow=arow.join(pd.DataFrame({\"4-layer Neural Net\": eval_score(5,data,\"mlp2\",train_size)},index=[len(data[0])]))\n",
    "\n",
    "    return arow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_names = [\"linear\", \"bayesian\", \"dt5\", \"dt8\", \"rf\", \"ada\", \"gb\", \"mlp1\", \"mlp2\"]\n",
    "def train_methods(data, train_size):\n",
    "    \"\"\"\n",
    "    Trains all models on the given data and returns a dictionary of the trained models\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for model_name in all_model_names:\n",
    "        avg_score, max_score, model = eval_score(100, data, model_name, train_size)\n",
    "        results[model_name] = avg_score, max_score, model\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_vector_df = pd.read_csv(\"/Users/noahwiley/Documents/Bike UROP/MeasureML-main/Frame Datasets/aero_data_augmented_id_cut.csv\")\n",
    "target_drag_df = pd.read_csv(\"/Users/noahwiley/Downloads/Aero/targetdf.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m/Users/noahwiley/Documents/Bike UROP/MeasureML-main/Frame Datasets/Model Tests/trained_models.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     model_dict \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"/Users/noahwiley/Documents/Bike UROP/MeasureML-main/Frame Datasets/Model Tests/trained_models.pkl\", \"rb\") as f:\n",
    "    model_dict = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
